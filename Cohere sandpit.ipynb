{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff9412f0",
   "metadata": {},
   "source": [
    "## Cohere SANDPIT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9a35fe",
   "metadata": {},
   "source": [
    "Models\n",
    "https://docs.cohere.com/docs/generation-card\n",
    "API Keys\n",
    "https://dashboard.cohere.com/api-keys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42da83e0",
   "metadata": {},
   "source": [
    "The endpoint has a number of settings you can use to control the kind of output it generates. The full list is available in the API reference, but letâ€™s look at a few:\n",
    "\n",
    "model - command or command-lite. Generally, lite models are faster while larger models will perform better.\n",
    "temperature - This parameter ranges from 1 to 5, and controls the randomness of the output. Higher values tend to generate more creative outcomes, and gives you the opportunity of generating various summaries for the same input text. It also might include more hallucinations. Use a higher value if for example you plan to perform a selection of various summaries afterwards.\n",
    "\n",
    "length - You can choose between short, medium and long. short summaries are roughly up to two sentences long, medium between three and five, and long might have more six or more sentences.\n",
    "\n",
    "format - You can choose between paragraph and bullets. Paragraph generates a coherent sequence of sentences, while bullets outputs the summary in bullet points.\n",
    "\n",
    "extractiveness - This parameter can be set at low, medium, high values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b946e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cohere\n",
    "api_key = input(str(\"Key:\"))\n",
    "co = cohere.Client(api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b635b7",
   "metadata": {},
   "source": [
    "## TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5699b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "text =\"It's an exciting day for the development community. Cohere's state-of-the-art language AI is now available through Amazon SageMaker. This makes it easier for developers to deploy Cohere's pre-trained generation language model to Amazon SageMaker, an end-to-end machine learning (ML) service. Developers, data scientists, and business analysts use Amazon SageMaker to build, train, and deploy ML models quickly and easily using its fully managed infrastructure, tools, and workflows. At Cohere, the focus is on language. The company's mission is to enable developers and businesses to add language AI to their technology stack and build game-changing applications with it. Cohere helps developers and businesses automate a wide range of tasks, such as copywriting, named entity recognition, paraphrasing, text summarization, and classification. The company builds and continually improves its general-purpose large language models (LLMs), making them accessible via a simple-to-use platform. Companies can use the models out of the box or tailor them to their particular needs using their own custom data.Developers using SageMaker will have access to Cohere's Medium generation language model. The Medium generation model excels at tasks that require fast responses, such as question answering, copywriting, or paraphrasing. The Medium model is deployed in containers that enable low-latency inference on a diverse set of hardware accelerators available on AWS, providing different cost and performance advantages for SageMaker customers.\"\n",
    "\n",
    "def test_cohere_installation(text):\n",
    "    try:\n",
    "        # Test cohere import\n",
    "        co.summarize(\n",
    "            text=text,\n",
    "            model='command',\n",
    "            length='medium',\n",
    "            extractiveness='medium'\n",
    "        )\n",
    "        print(\"Cohere is responding\")\n",
    "    except Exception as e:\n",
    "        print(\"Cohere installation test failed.\")\n",
    "        print(\"Error:\", str(e))\n",
    "        \n",
    "test_cohere_installation(text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0ed7ce",
   "metadata": {},
   "source": [
    "## SUMMARIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "40c5c8f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amazon Web Services (AWS) customers can now use Cohere's state-of-the-art language AI through Amazon SageMaker, a machine learning service. The Medium generation language model, which is available through AWS, can be used for tasks that require fast responses, such as question answering, copywriting, or paraphrasing. The model is deployed in containers that enable low-latency inference on a diverse set of hardware accelerators, providing different cost and performance advantages for SageMaker customers.\n"
     ]
    }
   ],
   "source": [
    "text =\"It's an exciting day for the development community. Cohere's state-of-the-art language AI is now available through Amazon SageMaker. This makes it easier for developers to deploy Cohere's pre-trained generation language model to Amazon SageMaker, an end-to-end machine learning (ML) service. Developers, data scientists, and business analysts use Amazon SageMaker to build, train, and deploy ML models quickly and easily using its fully managed infrastructure, tools, and workflows. At Cohere, the focus is on language. The company's mission is to enable developers and businesses to add language AI to their technology stack and build game-changing applications with it. Cohere helps developers and businesses automate a wide range of tasks, such as copywriting, named entity recognition, paraphrasing, text summarization, and classification. The company builds and continually improves its general-purpose large language models (LLMs), making them accessible via a simple-to-use platform. Companies can use the models out of the box or tailor them to their particular needs using their own custom data.Developers using SageMaker will have access to Cohere's Medium generation language model. The Medium generation model excels at tasks that require fast responses, such as question answering, copywriting, or paraphrasing. The Medium model is deployed in containers that enable low-latency inference on a diverse set of hardware accelerators available on AWS, providing different cost and performance advantages for SageMaker customers.\"\n",
    "\n",
    "response = co.summarize(\n",
    "    text=text,\n",
    "    model='command',\n",
    "    length='medium',\n",
    "    extractiveness='medium'\n",
    ")\n",
    "\n",
    "summary = response.summary\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64351520",
   "metadata": {},
   "source": [
    "## SENTIMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eeca5509",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The confidence levels of the labels are: [Classification<prediction: \"negative\", confidence: 0.995637, labels: {'negative': LabelPrediction(confidence=0.995637), 'positive': LabelPrediction(confidence=0.0043630055)}>, Classification<prediction: \"negative\", confidence: 0.9347263, labels: {'negative': LabelPrediction(confidence=0.9347263), 'positive': LabelPrediction(confidence=0.065273724)}>]\n"
     ]
    }
   ],
   "source": [
    "from cohere.responses.classify import Example\n",
    "\n",
    "classifications = co.classify(\n",
    "  model='embed-english-v2.0',\n",
    "  inputs=[\"This item was broken when it arrived\", \"This item broke after 3 weeks\"],\n",
    "  examples=[Example(\"The order came 5 days early\", \"positive\"), Example(\"The item exceeded my expectations\", \"positive\"), Example(\"I ordered more for my friends\", \"positive\"), Example(\"I would buy this again\", \"positive\"), Example(\"I would recommend this to others\", \"positive\"), Example(\"The package was damaged\", \"negative\"), Example(\"The order is 5 days late\", \"negative\"), Example(\"The order was incorrect\", \"negative\"), Example(\"I want to return my item\", \"negative\"), Example(\"The item\\'s material feels low quality\", \"negative\")])\n",
    "print('The confidence levels of the labels are: {}'.format(\n",
    "       classifications.classifications))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c658c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
